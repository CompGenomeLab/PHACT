Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	compute_score
	1

[Tue Jan 12 22:56:37 2021]
rule compute_score:
    input: /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/results/P01008/3_mltree/P01008.raxml.bestTree_unrooted, /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/results/P01008/4_codeml/P01008_codeml
    output: /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/results/P01008/5_scores/P01008_wol_param_CountNodes_1.csv, /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/results/P01008/5_scores/P01008_wl_param_CountNodes_1.csv
    log: /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/workflow/logs/rules/P01008_CountNodes_1_compute_score.err
    jobid: 0
    benchmark: /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/workflow/logs/benchmarks/P01008_CountNodes_1_compute_score.out
    wildcards: output_folder=/cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow, msa_name=P01008, pattern=CountNodes_1
    resources: cpus=2, mem_mb=8192, time_min=1200

Activating conda environment: /cta/users/eakkoyun/WORKFOLDER/phylogeny-workflow/workflow/.snakemake/conda/17731746
[Tue Jan 12 22:59:16 2021]
Finished job 0.
1 of 1 steps (100%) done
